{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to get data from two different subreddits and attempt to predict which subreddit a post comes from. Because we only have two subreddits we are working with this is a classification problem. To scrape the data I'm using the praw module below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the modules we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-09-03_14:48:28'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the call to the praw module. This makes scraping data from reddit much easier. If it wasn't for this wrapper we would need to get and parse a json file. This would be easy as it's just a series of python dictionaries but it would be tedious. All values have been replaced with stars for privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id='lTmx7ljJA-06sw',\n",
    "                     client_secret='DqoKcVA4JfGW1kPH2hDXO3o7zZM',\n",
    "                     user_agent='GA_test_Bot',\n",
    "                     username='GA_test5467943',\n",
    "                     password='kSYRwtPOY4W0mTderAT4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function I created to scrape data from Reddit. The values that are collected are the post title, the comments as a reddit comment tree, the author, if the post was guilded meaning if someone paid Reddit to reward the author of the post, The number of comments, the score which is the number of upvotes and downvotes, the authors flair text, the time created in utc, the post id, and the post body. The function accepts values to select the subreddit, the sorting catagory (hot, rising, ect.) and the number of posts to scrape. It then takes these values and stores them in a csv file that has a datetime stamp as the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reddit_Scraper(sub_reddit, catagory, posts):\n",
    "    title =[]\n",
    "    comments=[]\n",
    "    author=[]\n",
    "    guilded=[]\n",
    "    num_comments=[]\n",
    "    score=[]\n",
    "    pinned = []\n",
    "    subreddit=[]\n",
    "    author_flair_text=[]\n",
    "    created_utc=[]\n",
    "    r_id = []\n",
    "    body=[]\n",
    "    \n",
    "    if catagory == 0:\n",
    "        cat ='hot'\n",
    "        for submission in reddit.subreddit(sub_reddit).hot(limit=posts):\n",
    "            title.append(submission.title)\n",
    "            comments.append(submission.comments)\n",
    "            author.append(submission.author)\n",
    "            guilded.append(submission.gilded)\n",
    "            num_comments.append(submission.num_comments)\n",
    "            score.append(submission.score)\n",
    "            pinned.append(submission.pinned)\n",
    "            subreddit.append(submission.subreddit)\n",
    "            author_flair_text.append(submission.author_flair_text)\n",
    "            created_utc.append(submission.created_utc)\n",
    "            r_id.append(submission.id)\n",
    "            body.append(submission.selftext)\n",
    "            \n",
    "    elif catagory == 1:\n",
    "        cat='new'\n",
    "        for submission in reddit.subreddit(sub_reddit).new(limit=posts):\n",
    "            title.append(submission.title)\n",
    "            comments.append(submission.comments)\n",
    "            author.append(submission.author)\n",
    "            guilded.append(submission.gilded)\n",
    "            num_comments.append(submission.num_comments)\n",
    "            score.append(submission.score)\n",
    "            pinned.append(submission.pinned)\n",
    "            subreddit.append(submission.subreddit)\n",
    "            author_flair_text.append(submission.author_flair_text)\n",
    "            created_utc.append(submission.created_utc)\n",
    "            r_id.append(submission.id)\n",
    "            body.append(submission.selftext)\n",
    "            \n",
    "    elif catagory==2:\n",
    "        cat='rising'\n",
    "        for submission in reddit.subreddit(sub_reddit).rising(limit=posts):\n",
    "            title.append(submission.title)\n",
    "            comments.append(submission.comments)\n",
    "            author.append(submission.author)\n",
    "            guilded.append(submission.gilded)\n",
    "            num_comments.append(submission.num_comments)\n",
    "            score.append(submission.score)\n",
    "            pinned.append(submission.pinned)\n",
    "            subreddit.append(submission.subreddit)\n",
    "            author_flair_text.append(submission.author_flair_text)\n",
    "            created_utc.append(submission.created_utc)\n",
    "            r_id.append(submission.id)\n",
    "            body.append(submission.selftext)\n",
    "            \n",
    "            \n",
    "    elif catagory == 3:\n",
    "        cat='controvertial'\n",
    "        for submission in reddit.subreddit(sub_reddit).controversial(limit=posts):\n",
    "            title.append(submission.title)\n",
    "            comments.append(submission.comments)\n",
    "            author.append(submission.author)\n",
    "            guilded.append(submission.gilded)\n",
    "            num_comments.append(submission.num_comments)\n",
    "            score.append(submission.score)\n",
    "            pinned.append(submission.pinned)\n",
    "            subreddit.append(submission.subreddit)\n",
    "            author_flair_text.append(submission.author_flair_text)\n",
    "            created_utc.append(submission.created_utc)\n",
    "            r_id.append(submission.id)\n",
    "            body.append(submission.selftext)\n",
    "            \n",
    "    df_temp = pd.DataFrame({'title': title,\n",
    "                       'comments': comments,\n",
    "                       'author' :author,\n",
    "                       'guilded':guilded,\n",
    "                       'num_comments':num_comments,\n",
    "                       'score':score, \n",
    "                       'pinned':pinned,\n",
    "                       'subreddit':subreddit,\n",
    "                       'author_flair_text':author_flair_text,\n",
    "                       'created_utc':created_utc,\n",
    "                       'r_id':r_id,\n",
    "                       'body':body})\n",
    "    \n",
    "    tme = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    f_name='{}_{}_{}.csv'.format(tme,cat,sub_reddit)\n",
    "    df_temp.to_csv(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original plan involved scraping data from the quasi subreddit \"r/popular\" I assumed that  getting data from popular and sorting by hot, rising, new and controvertial. The hope was that I could detect a post in popular/rising and see if I could predict if it would go to hot, controvercial or not go anywhere. That went well but I found that popular/contrivercial had a large amount of racist material. I did not want to present this to the class so I developed a back up plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reddit_Scraper('popular',0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reddit_Scraper('popular',1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reddit_Scraper('popular',2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reddit_Scraper('popular',3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead I decided to simply get the posts from \"r/justnomil\" and \"r/raisedbynarcissists\" instead as they are interesting and have large body posts and not links. \n",
    "\n",
    "JustNoMil, JNM for short, is a forum for people to complain about their mother in laws. The forum is mostly for stories but there is some reqursts for advice. It has a upbeat feeling and the members call themselves \"drama llamas\"\n",
    "\n",
    "Raised by Narcissists, RBN, is a support group for people that have bad parents. This is a serious subreddit. In hindsite I probably should not have used this forum but I was on a deadline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reddit_Scraper('JUSTNOMIL',0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reddit_Scraper('raisedbynarcissists',0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reddit_Scraper('weddingplanning',0,100)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
